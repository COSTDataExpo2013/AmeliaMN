{
    "contents" : "sotc10 <- read.csv(\"sotc10.csv\")\norigNames <- names(sotc10)\n\n#sotc <- sotc10[sample(dim(sotc10)[1], 1000),]\nsotc <- sotc10\nsotc <- noNA\n\n#Cleaning and naming the data\n{There are a few repeated columns, or columns filled with NAs.\nsotc$QS3_02 <- NULL\nsotc$QS5_2 <- NULL\nsotc$Q7J <- NULL\nsotc$Q12 <- NULL\nsotc$Q16B <- NULL\nsotc$Q16C <- NULL\nsotc$Q16D <- NULL\nsotc$Q17 <- NULL\nsotc$Q27 <- NULL\nsotc$Q28 <- NULL\nsotc$Q29 <- NULL\nsotc$Q30 <- NULL\nsotc$Q31A <- NULL\nsotc$Q31B <- NULL\nsotc$Q31C <- NULL\nsotc$Q31D <- NULL\nsotc$Q31E <- NULL\nsotc$Q31F <- NULL\nsotc$Q31G <- NULL\nsotc$Q31H <- NULL\nsotc$QD3 <- NULL\nsotc$Q15VERA <- NULL\nsotc$Q15VERB <- NULL\nsotc$Q15VERAS <- NULL\nsotc$Q15VERBS <- NULL\nsotc$QD111R <- NULL\nsotc$QD112R <- NULL\nsotc$QD113R <- NULL\n# Recoding \"Yes, [] respondent available\" to gender. \nlevels(sotc$INTRO1)<- c(\"Female\", \"Male\")\n\nnames(sotc)[2] <- \"gender\"\nnames(sotc)[3] <- \"citystate\"\nnames(sotc)[4] <- \"county\"\nnames(sotc)[5] <-  \"zipcode\"\nnames(sotc)[6] <- \"age\"\nnames(sotc)[7] <- \"area_descrip\"\nnames(sotc)[8] <- \"further\"\nnames(sotc)[9] <- \"current_life\"\nnames(sotc)[10] <- \"future_life\"\nnames(sotc)[11] <- \"community_sat\"\nnames(sotc)[12] <- \"recommend\"\nnames(sotc)[13] <- \"proud\"\nnames(sotc)[14] <- \"perfect\"\nnames(sotc)[15] <- \"reputation\"\nnames(sotc)[16] <- \"problem1\"\nnames(sotc)[17] <- \"problem2\"\nnames(sotc)[18] <- \"problem3\"\nnames(sotc)[19] <- \"ratherlive\"\nnames(sotc)[20] <- \"five_years_ago\"\nnames(sotc)[21] <- \"five_years_future\"\nnames(sotc)[22] <- \"parks\"\nnames(sotc)[23] <- \"beauty\"\nnames(sotc)[24] <- \"highways\"\nnames(sotc)[25] <- \"affordable_housing\"\nnames(sotc)[26] <- \"job_opportunites\"\nnames(sotc)[27] <- \"public_schools\"\nnames(sotc)[28] <- \"colleges\"\nnames(sotc)[29] <- \"nightlife\"\nnames(sotc)[30] <- \"friends\"\nnames(sotc)[31] <- \"heathcare\"\nnames(sotc)[32] <- \"leadership\"\nnames(sotc)[33] <- \"care\"\nnames(sotc)[34] <- \"police\"\nnames(sotc)[35] <- \"arts\"\nnames(sotc)[36] <- \"community_events\"\nnames(sotc)[37] <- \"talented_grads\"\nnames(sotc)[38] <- \"immigrants\"\nnames(sotc)[39] <- \"minorities\"\nnames(sotc)[40] <- \"families_kids\"\nnames(sotc)[41] <- \"gay_lesbian\"\nnames(sotc)[42] <- \"seniors\"\nnames(sotc)[43] <- \"young_adults\"\nnames(sotc)[44] <- \"economy\"\nnames(sotc)[45] <- \"econ_better\"\nnames(sotc)[46] <- \"trust_government\"\nnames(sotc)[47] <- \"employment\"\nnames(sotc)[48] <- \"job_satisfaction\"\nnames(sotc)[49] <- \"company_workforce\"\nnames(sotc)[50] <- \"enough_income\"\nnames(sotc)[51] <- \"area_hiring\"\nnames(sotc)[52] <- \"representative_leaders\"\nnames(sotc)[53] <- \"treated_respectfully\"\nnames(sotc)[54] <- \"night_safety\"\nnames(sotc)[55] <- \"crime\"\nnames(sotc)[56] <- \"crime_increasing\"\nnames(sotc)[57] <- \"registered_vote\"\nnames(sotc)[58] <- \"volunteer\"\nnames(sotc)[59] <- \"public_meeting\"\nnames(sotc)[60] <- \"voted_local\"\nnames(sotc)[61] <- \"worked_change\"\nnames(sotc)[62] <- \"church\"\nnames(sotc)[63] <- \"festival\"\nnames(sotc)[64] <- \"donated_org\"\nnames(sotc)[65] <- \"donated_individual\"\nnames(sotc)[66] <- \"donated_shelter\"\nnames(sotc)[67] <- \"impact\"\nnames(sotc)[68] <- \"clubs\"\nnames(sotc)[69] <- \"friends_nearby\"\nnames(sotc)[70] <- \"friends_friends\"\nnames(sotc)[71] <- \"family_nearby\"\nnames(sotc)[72] <- \"talk_neighbors\"\nnames(sotc)[73] <- \"years_lived\"\nnames(sotc)[74] <- \"permanent_resident\"\nnames(sotc)[75] <- \"household_adults\"\nnames(sotc)[76] <- \"children\"\nnames(sotc)[77] <- \"under6\"\nnames(sotc)[78] <- \"six_12\"\nnames(sotc)[79] <- \"thirteen_17\"\nnames(sotc)[80] <- \"married\"\nnames(sotc)[81] <- \"education\"\nnames(sotc)[82] <- \"own_home\"\nnames(sotc)[83] <- \"income\"\nnames(sotc)[84] <- \"hispanic\"\nnames(sotc)[85] <- \"race\"\nnames(sotc)[86] <- \"race2\"\nnames(sotc)[87] <- \"race3\"\nnames(sotc)[88] <- \"white_hispanic\"\nnames(sotc)[89] <- \"phone_numbers\"\nnames(sotc)[90] <- \"cell_only\"\nnames(sotc)[91] <- \"have_cell\"\nnames(sotc)[92] <- \"cell_calls\"\n# THERE ARE EVEN MORE VARIABLES!!!\n\n# Okay, here's the deal. They called people up on the phone and asked them a bunch of questions (seriously, how long is this phone survey?)\n# They entered the data as it was given to them (although within a pre-decided data collection scheme)\n# Then, because they had CRAZILY decided to do everything on different Likert scales they recoded a bunch of data to be high-medium-low instead of numbers\n# So, almost all the variables are repeated in the data set\n# Then, they used the recoded variables to determine a couple of different measures, for example safety and civic involvedness. It's not clear what they did for these numbers \n  \nsotc$current_life <- factor(sotc$current_life, levels(sotc$current_life)[c(1:2,13,3:12)])\nsotc$future_life <- factor(sotc$future_life, levels(sotc$future_life)[c(1:2,13,3:12)])\nsotc$community_sat <- factor(sotc$community_sat, levels(sotc$community_sat)[c(6, 5, 1:3, 4)])\nsotc$seniors <- factor(sotc$seniors, levels(sotc$seniors)[c(4, 1:3, 5)])}\n\n# How many questions are there at each number of items on the scale?\n{\nnumLevels <- 0\nfor (i in 2:92){\n  numLevels[i] <- length(levels(as.factor(sotc[,i])))\n}\nnumLevels <- numLevels[-c(3, 4, 6, 16:18, 73, 75)]\nresp <- qplot(numLevels,binwidth=1,xlab=\"Number of levels on the scale\", ylab=\"Number of questions using the scale\", main=\"Distribution of various scale lengths used in 2010 survey\")\nresp <- resp +scale_x_continuous(breaks=seq(from=0, to=15, by=2))}\n\n\nsatisfaction <- summary(sotc$community_sat)/length(sotc$community_sat)\n\n# Tableplot, helps see missing data\n{library(tabplot)\ntableplot(sotc, select=c(5:10), sortCol=current_life)}\n\n# I've been thinking about this in a couple ways. First, there's individual-level data\n# Then, there's city-level data. I've used the ggmap package to find the lats and lons of the cities\n# and put in the corresponding names. Probably I should have a data set that has the information that is only at the city level\n# For example, the measures the Knight foundation came up with.\n\n# Here's the lat/lon and city name data\n{geocoded <- dget(\"latlonsotc.robj\")\n\n# Part of the process for getting it\n#geocoded$citystate <- levels(sotc$citystate)\n}\n\n# Making some maps\n{\ngeocoded$oh10 <- summary(sotc10$QSB)/popdata$CENSUS2010POP\ngeocoded$oh9 <- summary(sotc09$QSB)/popdata$POPESTIMATE2009\ngeocoded$oh8 <- summary(sotc08$QSB)/popdata$POPESTIMATE2008\n\nbigfirst <- order(geocoded$oh8, decreasing=TRUE)\nMakeMap(geocoded$lat[bigfirst], geocoded$lon[bigfirst], scaleby=geocoded$oh8[bigfirst])\nsymbols(x=rep(-13569284, times=3), y=c(3086741,3000000,2980000), circles=radius2, inches=0.35, add=TRUE, bg=\"blue\")\ntext(rep(-13400000, times=3), c(3206741,3100000,3000000), labels=c(\"5%\", \"0.5%\", \"0.05%\"), pos=4, cex=0.75)\n}\n\n\n# Decided to put it in with the sotc data so every individual would have a (crappy and inaccurate) set of coordinates\n# Probably should not have taken this approach\n{\n# sotc$lat <- 0\n# sotc$lon <- 0\n# for (i in 1:length(levels(sotc$citystate))){\n#   cityname <- levels(sotc$citystate)[i]\n#   sotc$lat[which(sotc$citystate==cityname)] <- geocoded$lat[geocoded$citystate==cityname]\n#   sotc$lon[which(sotc$citystate==cityname)] <- geocoded$lon[geocoded$citystate==cityname]\n# }\n\n# dput(sotc, file=\"cleanedSotc10.robj\")\n# sotc2 <- dget(\"cleanedSotc10.robj\")\n}\n# Instead, I should be taking the city-level data and putting it in the geocoded data set\n# Take a look at this:\n\nView(sotc[,c(\"citystate\", \"THRIVING\", \"STRUGGLI\", \"SUFFERIN\", \"TOTALN\")])\n\n# Well, it looks like there should only be one value for each city, but check these out\nlength(levels(sotc$citystate))\nlength(levels(as.factor(sotc$SUFFERIN)))\nlength(levels(as.factor(sotc$THRIVING)))\nlength(levels(as.factor(sotc$TOTALN)))\n\nthriv <- \n\nfor (i in 1:length(levels(sotc$citystate))){\n  table(sotc[sotc$citystate==levels(sotc$citystate)[i],]$THRIVING)\n  \n}\n\n# Interesting plot, need to think more about:\nplot(table(sotc$citystate,sotc$THRIVING), las=2)\n\n\n\n\n\n\nggplot(sotc, aes(gender)) + geom_bar(aes(y = (..count..)/sum(..count..)))\n\n# Structure of the data\nstr(sotc)\n\n\n# Ages of respondents\nbarplot(tapply(sotc$age, sotc$citystate, mean), las=2)\n# Looks pretty random\n\n# How are seniors treated?\nggplot(sotc, aes(x=seniors))+geom_bar()+xlab(\"How seniors are treated\")+ggtitle(\"Whole survey population beliefs about senior treatment\")\nggplot(sotc[sotc$age>55,], aes(x=seniors))+geom_bar()\nggplot(sotc[sotc$age<55,], aes(x=seniors))+geom_bar()\n\n# Could look at the same thing with teenagers\n\n# Maybe one measure is how well the community agrees with the people\n# Like, if the community says it's good for seniors and seniors say it's good for seniors, that's good\n# But is it good or bad if the community says it's bad and the seniors say it's bad?\n\n# Should also try the Likert scale plots. Looks cool!\n\nbaby <- sotc[1:100, c(\"community_sat\", \"seniors\")]\n\n# Yes/no questions\n# We can look at all the yes/no questions together using percentages\n{# Pick out the appropriate variables\ntwolevel <- c(\"registered_vote\", \"volunteer\", \"public_meeting\", \"voted_local\", \"worked_change\", \"church\", \"festival\", \"donated_org\", \"donated_individual\", \"donated_shelter\")\n\n# Which factor levels are positive?\npositive <- \"Yes\"\nnegative <- \"No\"\n\n# Doing the yes/nos overall\ndfall <- data.frame()\nfor (i in 1:length(twolevel)){\n  tmp <- data.frame(Question=twolevel[i], prop.table(table(sotc[,twolevel[i]])))\n  dfall <- rbind(dfall, tmp)\n}\nnames(dfall) <- c(\"Question\", \"Response\", \"Freq\")\npos <- dfall[dfall$Response %in% positive,]\nneg <- dfall[dfall$Response %in% negative,]\nneg$Freq <- -neg$Freq\ntheorder <- order(pos$Freq, decreasing=T)\npos$Question <- factor(pos$Question, levels=levels(pos$Question)[rev(theorder)])\nneg$Question <- factor(neg$Question, levels=levels(neg$Question)[rev(theorder)])\n\nbaseplot <- ggplot(dfall) + aes(Question, Freq, fill = Response) #+facet_wrap(~citystate)\nbaseplot <- baseplot + geom_bar(data = neg, stat = \"identity\") + geom_bar(data = pos, stat = \"identity\")\nbaseplot <- baseplot +coord_flip()+ggtitle(\"Yes/no questions\")+scale_y_continuous(breaks=c(-1.0, -.5, 0, .5, 1),labels=c(\"100%\",\"50%\", \"0\", \"50%\", \"100%\"))\nbaseplot <- baseplot + xlab(\"\")\nbaseplot <- baseplot + scale_x_discrete(labels=rev(c(\"Registered to vote\", \"Voted in the local election\", \"Donated money to a local organization\", \"Attended a local event\", \"Gave money or food to an individual\", \"Participated in a church event\", \"Performed local volunteer work\", \"Worked with other residents to make change\", \"Attended a local public meeting\", \"Provided free shelter to an individual\")))\nbaseplot \n\n# Create a loop that calculates the percentages of cases in each factor level for each city\ndfcities <- data.frame()\nfor (j in 1:length(levels(sotc$citystate))){\n  thiscity <- subset(sotc, citystate==levels(sotc$citystate)[j])\n  for (i in 1:length(twolevel)){\n    tmp <- data.frame(levels(sotc$citystate)[j], Question=twolevel[i], prop.table(table(thiscity[,twolevel[i]])))\n    dfcities <- rbind(dfcities, tmp)\n  }\n}\nnames(dfcities) <- c(\"citystate\", \"Question\", \"Response\", \"Freq\")\n\n\n\n\n\ndfall$citystate <- \"Overall\"\nnames(dfall) <- c(\"Question\", \"Response\", \"Freq\", \"citystate\")\ndfcities <- rbind(dfall, dfcities)\ndfcities$citystate <- factor(dfcities$citystate)\nlevels(dfcities$citystate) <- levels(dfcities$citystate)[c(20,1:19,21:27)]\n# Subset the positive and negative responses\npos <- dfcities[dfcities$Response %in% positive,]\nneg <- dfcities[dfcities$Response %in% negative,]\n# pos = ddply(pos, .(\"citystate\", \"Question\"), transform, ypos = cumsum(Freq) - 0.5*Freq)\n# neg = ddply(neg, \"Question\", transform, ypos = rev(cumsum(rev(Freq)) - 0.5*rev(Freq)))\nneg$Freq <- -neg$Freq\n# neg$ypos <- -neg$ypos\n# neg$Response <- ordered(neg$Response, levels = rev(levels(neg$Response)))\n# pos$Question <- factor(pos$Question, levels=levels(pos$Question)[rev(theorder)])\n# neg$Question <- factor(neg$Question, levels=levels(neg$Question)[rev(theorder)])\n# Don't actually need this\n#theorder <- order(pos$Freq, decreasing=T)\n# pos <- pos[theorder,]\n# neg <- neg[theorder,]\n\n\nbaseplot <- ggplot(dfcitiesYes) + aes(Question, diff, fill = col) +facet_wrap(~citystate) + geom_bar()\n#baseplot <- baseplot + geom_bar(data = neg, stat = \"identity\") + geom_bar(data = pos, stat = \"identity\")\nbaseplot <- baseplot +coord_flip()+ggtitle(\"Difference from overall rates\")\nbaseplot <- baseplot + guides(fill=FALSE)\n#+scale_y_continuous(breaks=c(-1.0, -.5, 0, .5, 1),labels=c(\"100%\",\"50%\", \"0\", \"50%\", \"100%\"))\nbaseplot <- baseplot + ylab(\"\") +xlab(\"\")\nbaseplot <- baseplot + scale_x_discrete(labels=rev(c(\"Registered to vote\", \"Voted in the local election\", \"Donated money to a local organization\", \"Attended a local event\", \"Gave money or food to an individual\", \"Participated in a church event\", \"Performed local volunteer work\", \"Worked with other residents to make change\", \"Attended a local public meeting\", \"Provided free shelter to an individual\")))\nbaseplot\n# Something wrong with this right now, and it might not reflect the data set as a whole\n}\n\n# Frequency polygons\nggplot(sotc, aes(community_sat))+ geom_freqpoly(aes(group=gender, color=gender))\n\n\n# Population data\n{popdata <- dget(\"popdata.robj\")\npopdata <- popdata[,c(1,4:16)]\nnames(popdata)[1]<- \"citystate\"\nrow.names(popdata) <- NULL\npopdata <- t(popdata)\npopdata <- data.frame(popdata)\ncolnames(popdata) <- popdata[1,]\npopdata <- popdata[2:14,]\n\nfor (i in 1:length(levels(sotc$citystate))){\n  sotc$pop2010[sotc$citystate==levels(sotc$citystate)[i]] <- popdata$CENSUS2010POP[popdata$levels.sotc10.QSB==levels(sotc$citystate)[i]]\n}\n}\n\n# I guess I need to think about what exactly I want to plot!!!! Seems like recasting the data might not have fixed my woes.\n\n\n\n# Macon, GA has a bunch of data where they basically only answered one question: community_sat. Same thing with Akron, OH\n# Charlotte, NC and probably Detroit, MI; Miami, FL; and on and on! Lets see what the percentage is for each community.\n\nsummary(sotc10[is.na(sotc10$QN1A),]$QSB)\n\n4880/20271\n# So about 25% of the data is essentially missing. They only answered the one question (+ demographics). Helps me focus on that question, though!\n# community_sat is the crucial question. \n\n# Question, is there a relationship between being missing and something else? For example, did they just add a few more responses in certain cities?\n\n# This is the only question that I want to use the full 2010 data set for. Lets do one of those Likert scale plots\n\n\n\n\npopdata$oh6 <- 0\npopdata$oh7oh8<- (popdata$POPESTIMATE2008-popdata$POPESTIMATE2007)/popdata$POPESTIMATE2008\npopdata$oh8oh9<- (popdata$POPESTIMATE2009-popdata$POPESTIMATE2008)/popdata$POPESTIMATE2009\npopdata$oh09oh10 <- (popdata$CENSUS2010POP-popdata$POPESTIMATE2009)/popdata$CENSUS2010POP\npopdata$gro10 <- TRUE\npopdata$gro10[popdata$oh09oh10<0] <- FALSE\n\ntmp <- melt(popdata)\ntmp <- tmp[tmp$variable==\"oh09oh10\" | tmp$variable==\"oh8oh9\" | tmp$variable==\"oh7oh8\" | tmp$variable==\"oh6\",]\nnames(tmp) <- c(\"citystate\", \"city\", \"state\", \"year\", \"value\")\ntmp$year <- factor(tmp$year)\ntmp$year <- factor(tmp$year, levels=levels(tmp$year), labels=c(\"2007\", \"2008\", \"2009\", \"2010\"))\nbaseplot <- ggplot(tmp, aes(x=year, y=value)) + geom_line(aes(group=citystate, color=gro10))+  geom_dl(aes(label=citystate), method=\"last.points\")\nbaseplot + theme(element_text(size=8))\n# ARGH! Words are too big. The right idea, though.\n\n\n\n",
    "created" : 1374097554041.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "8|1|142|72|\n145|1|152|65|\n158|1|159|53|\n167|1|171|0|\n174|1|183|0|\n188|1|199|0|\n253|1|326|0|\n333|1|345|0|\n",
    "hash" : "4284979184",
    "id" : "69D725B3",
    "lastKnownWriteTime" : 1375128377,
    "path" : "~/Dropbox/RStudioStuff/RStudioStuff/WorkingDocuments/SoulOfCommunity/sotcCode.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}