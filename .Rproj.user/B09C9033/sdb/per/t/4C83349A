{
    "contents" : "\\documentclass[smallextended]{svjour3}       % onecolumn (second format)\n\\RequirePackage{fix-cm}\n\\smartqed% flush right qed marks, e.g. at end of proof\n\\usepackage{graphicx}\n\\usepackage[round]{natbib}\n\n\n\\begin{document}\n\\journalname{Computational Statistics}\n\\title{Community engagement and subgroup meta-knowledge: Some factors in the soul of a community}\n\n\n\\titlerunning{Community engagement and subgroup meta-knowledge}        % if too long for running head\n\n\\author{Amelia McNamara}\n\\institute{A. McNamara \\at\n              8125 Math Sciences Bldg. \\\\\n              Los Angeles, CA 90095-1554 \\\\\n              \\email{amelia.mcnamara@stat.ucla.edu}\n}\n\n\\date{Received: date / Accepted: date}\n\\maketitle\n\n\n\n\\begin{abstract} The Knight Foundation collects data to determine what factors impact community satisfaction, local GDP growth, and interest in Knight news publications. For the 2013 Data Expo at the Joint Statistical Meetings, many participants created graphical explorations of these data. This article focuses on the idea of community meta-knowledge, which is essentially majority group empathy or understanding of how minorities experience their community. For example, the survey asks participants to rate their community ``as a place for senior citizens,'' on a 5-point Likert scale. A city where seniors rated their community in the same way as non-seniors is defined as a community with high meta-knowledge about conditions for seniors. Three minority groups were explored: seniors, families with young children, and racial minorities. In most communities, people outside the minority group tended to under-rate their community, compared to those in the minority group. However, there were some exceptions. \n\\keywords{2013 Data Exposition, R, ggplot2, Likert scales, meta-knowledge}\n\\end{abstract}\n\n\\section{Introduction}\n\\label{intro}\nStudies have shown that increasing empathy is the best way to improve intergroup relations \\citep{SteFin1999}. Therefore, it is of interest to quantify the typical level of empathy in communities across the United States. The Knight Foundation data provides a window to a factor which could be thought of as a proxy for empathy, namely community meta-knowledge. We are defining meta-knowledge as community awareness by those outside a specific subgroup about the conditions for people inside the subgroup. The primary attempt of this article is to answer the question ``Are people outside a specific subgroup aware of the quality of their community for people in that subgroup?\" and then, ``do communities with high meta-knowledge (those where people outside the subgroup understood conditions for minorities) have higher community satisfaction rates than those with low meta-knowledge?\"\n\nThis article is one of several related to the Knight Foundation community data from the 2013 Data Expo. For more information on the Expo and the data sets, see \\citep{HofWic20XX}.\n\n\\section{The Data}\n\\label{data}\nThe Knight Foundation collects survey data on 26 communities where the Knight brothers own newspapers, including San Jose, CA, State College, PA, Palm Beach, FL, and St. Paul, MN. The foundation has data for three years, starting in 2008. Each data set includes approximately 20 demographic questions and 50-80 survey questions, depending on how distinct questions are defined. The aim of the survey is to gauge what factors are important to community attachment, and it includes questions on a variety of subjects, from ``how satisfied are you with this community as a place to live?\" to ``how many minutes is your daily commute?\"\n\nThe survey is conducted over the phone by Gallup Poll, and can take place in either English or Spanish. Gallup also performs data analysis for the Knight Foundation, and their yearly reports are available on the Knight Foundation website \\citep{KF2008, KF2009, KF2010}. \n\nThe existing data analysis from Gallup is related to a metric they call ``Community Attachment.\" It is difficult to pin down what this variable means, but it's a composite metric composed of Community Loyalty and Community Passion. Both of those metrics, in turn, are composed of several variables. Community Loyalty includes how likely a person says they are to stay in that particular area, how much they would recommend it to friends, and their outlook for the community's future \\citep{KF2010}. Community Passion is composed of variables on connectedness and community pride. So, Community Attachment is already a model of what Gallup believes is important to strong communities. The Gallup team has discovered that this composite variable is positively correlated with local Gross Domestic Product (GDP) growth \\citep{KF2010b}. Because of this relationship, the analysis from Gallup is focused on what other factors correlate with Community Attachment (and therefore, with local GDP growth). \n\nWhile the Gallup Poll analysis is interesting, it does raise the question of multicolinearity, as factors that are correlated with Community Attachment may simply be correlated with one of the variables that was used to compose it, and may not actually have an impact on local GDP growth. \n<<packages, echo=FALSE>>=\nrequire(knitr)\n@ \n<<chunkoptions, echo=FALSE, include=FALSE>>=\nopts_chunk$set(echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, error=FALSE)\nrequire(dplyr)\nrequire(ggplot2)\nrequire(scales)\nrequire(RColorBrewer)\nrequire(ggmap)\nrequire(xtable)\n@\n<<readdata>>=\nsotc10 <- read.csv(\"data/sotc10.csv\")\nsotc09 <- read.csv(\"data/sotc09.csv\")\nsotc08 <- read.csv(\"data/sotc08.csv\")\n@\n<<renaming>>=\nrenameData <- function(datasetname){\n  plyr::rename(datasetname,c(\"INTRO1\" = \"gender\", \"QSB\" = \"citystate\", \"QS3\"=\"county\", \"QS3_02\"=\"county2\", \"QS3A\"=\"zipcode\", \"QD1\"=\"age\", \"QS4\"=\"area_descrip\", \"QS5\"=\"further\", \"QS5_2\"=\"further2\", \"QN1A\"=\"current_life\", \"QN1B\"=\"future_life\", \"QCE1\"=\"community_sat\",\"QCE2\"=\"recommend\",\"Q3A\"=\"proud\", \"Q3B\"=\"perfect\", \"Q3C\"=\"reputation\", \"Q4_1\"=\"problem_1\", \"Q4_2\"=\"problem_2\", \"Q4_3\"=\"problem_3\", \"Q4_1_1\"=\"problem_1\", \"Q4_1_2\"=\"problem_2\", \"Q4_1_3\"=\"problem_3\",\"Q4_2_1\"=\"problem_4\", \"Q4_2_2\"=\"problem_5\", \"Q4_2_3\"=\"problem_6\",\"Q4_3_1\"=\"problem_7\", \"Q4_3_2\"=\"problem_8\", \"Q4_3_3\"=\"problem_9\",\"Q5\"=\"rather_live\", \"Q6\"= \"five_years_ago\", \"Q6A\" = \"five_years_future\", \"Q7A\"= \"parks\", \"Q7B\"= \"beauty\", \"Q7C\"= \"highways\", \"Q7D\"= \"affordable_housing\", \"Q7E\" =  \"job_opportunites\", \"Q7F\"=  \"public_schools\", \"Q7G\" = \"colleges\", \"Q7H\"= \"nightlife\", \"Q7I\"= \"friends\", \"Q7J\" = \"raise_kids\", \"Q7K\" = \"heathcare\", \"Q7L\" =\"leadership\", \"Q7M\" = \"care\", \"Q7N\"= \"police\", \"Q7O\" = \"arts\", \"Q7P\" =  \"community_events\", \"Q8A\" = \"talented_grads\", \"Q8B\" = \"immigrants\", \"Q8C\"= \"minorities\", \"Q8D\"= \"families_kids\", \"Q8E\" = \"gay_lesbian\", \"Q8F\" = \"seniors\", \"Q8G\" = \"young_adults\", \"Q9\" = \"economy\", \"Q10\" = \"econ_better\", \"Q10A\" = \"trust_government\", \"Q11\" = \"employment\", \"Q12\" = \"commute\", \"Q13\" = \"job_satisfaction\", \"Q14\" = \"company_workforce\", \"Q15\" = \"enough_income\", \"Q15AA\" = \"area_hiring\", \"Q15AB\" = \"representative_leaders\", \"Q16A\" = \"treated_respectfully\", \"Q16B\" = \"well_rested\", \"Q16C\" = \"high_stress\", \"Q16D\" = \"learned_yest\", \"Q17\" = \"stress_source\", \"Q18\" = \"night_safety\", \"Q19\" = \"crime\", \"Q20\" = \"crime_increasing\", \"Q21\"=  \"registered_vote\", \"Q22A\" = \"volunteer\", \"Q22B\" = \"public_meeting\", \"Q22C\"= \"voted_local\", \"Q22D\" = \"worked_change\", \"Q22E\" = \"church\", \"Q22F\" = \"festival\", \"Q22G\" = \"donated_org\", \"Q22H\" = \"donated_individual\", \"Q22I\" = \"donated_shelter\", \"Q22_A\" = \"impact\", \"Q23\" = \"clubs\", \"Q24\" = \"friends_nearby\", \"Q24A\" =  \"friends_friends\", \"Q25\"= \"family_nearby\", \"Q26\"= \"talk_neighbors\", \"QD2\" = \"years_lived\", \"QD2A\" =\"permanent_resident\", \"QD3\" = \"work_cat\", \"QD3A\" = \"household_adults\", \"QD4\" = \"children\", \"QD5A\" = \"under6\", \"QD5B\" = \"six_12\", \"QD5C\" = \"thirteen_17\", \"QD6\" = \"married\", \"QD7\"= \"education\", \"QD8\" = \"own_home\", \"QD9\"= \"income\", \"QD10\" = \"hispanic\", \"QD111\" = \"race\", \"QD112\" = \"race2\", \"QD113\" = \"race3\", \"QD12\" = \"white_hispanic\", \"QD13\" = \"phone_numbers\", \"QD13A\" = \"cell_only\", \"QD13B\" = \"have_cell\", \"QD13C\" = \"cell_calls\"))\n}\n\n\nsotc10 <- renameData(sotc10)\nsotc09 <- renameData(sotc09)\nsotc08 <- renameData(sotc08)\n@\n\n\\subsection{Community Survey Rates}\n\\label{maprates}\nAs mentioned above, the data were collected by Gallup through telephone surveys in 2008, 2009, and 2010. Participants were a random sample of adults living in 26 ``communities\" (cities or metro areas of the United States), and at least 400 people were surveyed in each community. The data from 2008 and 2009 had \\Sexpr{dim(sotc08)[1]} and \\Sexpr{dim(sotc09)[1]} responses, respectively, while the data from 2010 contained \\Sexpr{dim(sotc10)[1]} observations. Because the data sets surveyed the same 26 communities, we can calculate the average number of survey participants in each community. In 2008, that average was \\Sexpr{floor(dim(sotc08)[1]/26)} people, in 2009, \\Sexpr{floor(dim(sotc09)[1]/26)} people and in 2010, \\Sexpr{floor(dim(sotc10)[1]/26)} people. The difference in average number of survey participants will be discussed further in Section \\ref{missingdata}. \n\nIn most communities, approximately 400 people were interviewed, but certain communities were surveyed much more. It appears that the Knight Foundation was trying to survey places at an approximately similar rate, which is why Philadelphia (for example) was surveyed 1633 times in 2010. To see which places were over- or under-represented in the survey, see Figure \\ref{fig:surveyrates} for plots showing the percentage of the community that was polled for each polling year.\n\nThe population data for Figure \\ref{fig:surveyrates} came from the Intercensal population estimates compiled by the Census Bureau. Population estimates are calculated each year between Census years. The estimates do not vary much from the decennial Census count, but yearly estimates were used for the sake of having different population numbers from year to year. For example, the 2010 Census count of the population of Palm Beach, FL was 8,348. In 2009, the estimate was 8,456, and in 2008 it was 8,631. \n\nFigure \\ref{fig:surveyrates} shows the percentage of the community that was polled, and percentages hover around a mean of 0.07\\%, with lots of variation. Palm Beach, FL always looks over-represented because the community is small in absolute number of residents and the minimal sample size of 400 was always used, leading to a polling rate around 4\\%. Large communities like Philadelphia, PA, look under-represented, with a rate around 0.01\\%. In addition, there is some variation over time, especially on the East side of the US. For example, Akron, OH begins with a polling rate of 0.01\\%, which rises to 0.07\\% and then 0.09\\%, as a result of polling increasing from around 400 residents to more than 1700. It's not clear why Gallup made these polling decisions. \n\n<<gettinggeodata>>=\nplacesPop <- dget(\"data/popdata.robj\")\n\npercent1 <- summary(sotc10$citystate)/placesPop$CENSUS2010POP\npercent1 <-c(percent1, summary(sotc09$citystate)/placesPop$POPESTIMATE2009)\npercent1 <- c(percent1, summary(sotc08$citystate)/placesPop$POPESTIMATE2008)\n\npopData <- data.frame(year=c(rep(2010, 26), rep(2009, 26), rep(2008, 26)), percent=percent1)\npopData$percent <- popData$percent*100\npopData$citystate <- c(rep(levels(sotc10$citystate),3))\n@\n\n<<surveyrates, fig.align=\"left\", fig.cap=\"Yearly survey percentages, displayed on a log scale. Notice that some communities are always over-surveyed (for example, Palm Beach, FL) and some always appear under-surveyed (for example, Long Beach, CA). The East side of the United States experiences an overall raise in survey rates over time, while the West side stays stable.\", out.width=\"\\\\linewidth\",fig.width = 9.5,fig.height=8.5>>=\n\np <- ggplot(aes(x=year, y=percent), data=popData)+facet_wrap(~citystate, ncol=5)+geom_line()+scale_x_continuous(breaks=c(2008, 2008.5, 2009, 2009.5, 2010), labels=c(\"2008\",\"\", \"2009\", \"\", \"2010\"))+scale_y_log10(breaks=c(0.04, 0.4, 4))+xlab(\"Year\")+ylab(\"Percent of community surveyed\")\np\n@\n\n\\subsection{Scale Lengths}\nThe majority of the Knight data is in the form of responses to survey questions, and most survey questions were answered on a Likert scale~\\citep{Lik1932}. However, there was little consistency in the number of levels for the scales. The most common scale was a five-point scale, as in ``Not at all satisfied, 2, 3, 4, Extremely satisfied'' or ``Very bad, 2, 3, 4, Very good.'' However, many other scales wordings (and scale sizes) were used. For the yearly distribution of scale lengths, see Figure \\ref{fig:LikertSizes}.\n\n<<LikertSizes, fig.cap=\"Scale length distributions for each year of the survey. Notice that the distribution from 2008 is centered around 7, and the 2009 and 2010 distributions are centered around 5. All three distributions have large variation, suggesting that the Knight surveys were quite complex.\",out.width=\"\\\\linewidth\",fig.width = 9.5,fig.height=7.5>>=\npullLevels <- function(dataset, range){\n  numLevels <- NA\n  for (i in range){\n    numLevels[i] <- length(levels(as.factor(dataset[,i])))\n  }\n  return(numLevels)\n}\n\n#Removing the ones that don't make sense-- listing problems, in particular\n\n# For sotc10, this works:\nnumLevels10 <- pullLevels(sotc10, c(11:80))\nnumLevels10[which(numLevels10>25)] <- NA\n\n#For sotc09\nnumLevels09 <- pullLevels(sotc09, c(11:70))\nnumLevels09[16:24] <- NA\n\n#For sotc08\nnumLevels08 <- pullLevels(sotc08, c(9:64))\n# This takes out the problem questions as well as the commute question\nnumLevels08[which(numLevels08>20)] <- NA\n\nnumLevels <- data.frame(levels=c(numLevels08, numLevels09, numLevels10), year=c(rep(2008, times=length(numLevels08)), rep(2009, times=length(numLevels09)), rep(2010, times=length(numLevels10))))\n\nresp<- ggplot(numLevels, aes(x=levels))+geom_histogram(breaks=seq(from=0, to=15, by=1))+facet_grid(.~year)+labs(x=\"Number of levels on the scale\", y=\"Number of questions using the scale\", title=\"Distribution of scale lengths used in surveys\")+theme(strip.text=element_text(size=14))\nresp\n@\n\nThe varied lengths of response scales and the different phrasing of scales even with the same length suggests that this survey was quite long and complex to complete. And though the survey maintains the scale lengths for individual questions over the years, Gallup rescales all the questions down to a 3-point scale to make their analysis simpler. The complete data set provided by the Knight Foundation includes between \\Sexpr{dim(sotc08)[2]} and \\Sexpr{dim(sotc10)[2]} variables, depending on the year, but fully half of them are rescaled versions of the original questions. While some researchers have suggested that a 3-point scale is enough \\citep{JacMat1971}, discarding data seems wasteful, especially if participants have gone to the trouble of rating on a 5- or 7-point scale. So, the remainder of this analysis works on the unscaled variables. \n\n\\subsection{Missing Data}\n\\label{missingdata}\nWhile the Gallup reports claim the telephone surveys only took 15 minutes, the number of variables collected and the wide range of response scales seems to indicate a much larger time commitment. This raises the question of whether everyone who began the survey completed it. And, as mentioned in Section \\ref{maprates}, the 2010 data contained many more observations than previous years. The explanation for this difference is missing data, presumably related to surveys that were not fully completed. \n\n<<missingmatch>>=\nmatchup1 <- length(which(which(is.na(sotc10$recommend)) %in% which(is.na(sotc10$college))))\nmatchup2 <- length(which(which(is.na(sotc10$college)) %in% which(is.na(sotc10$registered_vote))))\n@\n\nIn order to explore this, we study the pattern of missing data within the 2010 data set. This data set includes a large number of responses that are extremely sparse, containing almost no completed survey questions, but generally completed demographic information. For example, the question ``How likely are you to recommend this community to a friend or associate as a place to live?'' has \\Sexpr{sum(is.na(sotc10$recommend)==TRUE)} missing values, and the question ``The overall quality of the colleges and universities'' has \\Sexpr{sum(is.na(sotc10$college)==TRUE)} missing values. Just between those two questions, the overlap of missing values for both questions is \\Sexpr{matchup1}. In other words, almost all the entries that are missing a response to the question about recommending the community are also missing a response to the question about colleges. Similarly, there are \\Sexpr{matchup2} respondents missing both the question about colleges and the question ``Are you registered to vote?''\n\nThese questions were chosen arbitrarily, but the pattern is almost the same no matter which pair of survey questions was selected. As a result, we chose to use the question about recommending the community to a friend or associate as a proxy for the overall missing data. That is, if the response was missing an answer to that question, we considered it to be a ``missing'' response. The particular question was selected as an indicator of missing data because it was the first question on the survey (in order of the survey script) to have this scale of missing data. Better methods could have been used, for example setting a cutoff number of missing questions within a single respondent, but this seemed to be fairly accurate for our purposes. \n\nIn order to be consistent, we have considered data missing in 2008 and 2009 if there was no response to the question ``How likely are you to recommend this community to a friend or associate as a place to live?'' even though the 2008 and 2009 data do not show the same correspondence between that question being missing and the rest of the responses being almost completely sparse. Table \\ref{missingtable} shows the percentage of data designated as missing for each survey year. While the 2008 and 2009 data sets are almost complete, the 2010 data set has about 25\\% missing data.\n\nInterestingly, with the incomplete responses removed, the 2010 data set is reduced to ~15,000 observations, which is much closer to the ~14,000 observations the two prior years. This suggests that incomplete responses were removed in previous years, or that some new survey methodology (i.e. a ``short form'') was introduced in 2010. \n\n<<missingdatatable, results=\"asis\">>=\nmissing10 <- group_by(sotc10, recommend == \"NA\") %>% summarise(n = n()) \nmissing09 <- group_by(sotc09, recommend == \"NA\") %>% summarise(n = n()) \nmissing08 <- group_by(sotc08, recommend == \"(Refused)\") %>% summarise(n = n()) \nmissing <- c(missing08$n[2], missing09$n[2], missing10$n[2])\nmissingtable <- as.matrix(data.frame(Year=c(2008, 2009, 2010), Missing=missing, Total=c(dim(sotc08)[1], dim(sotc09)[1], dim(sotc10)[1]), Percent=missing/c(dim(sotc08)[1], dim(sotc09)[1], dim(sotc10)[1])*100))\nrownames(missingtable) <- NULL\nprint(xtable(x=missingtable,caption=\"Percent of missing data from surveys. The 2010 survey has almost 25 percent missing data. The total number of entries in 2010 is also much larger, suggesting that the 2008 and 2009 datasets used a different criteria for inclusion of entries.\", display=c(\"d\", \"d\", \"d\",\"d\", \"f\"), label=\"missingtable\"),include.rownames=FALSE)\n@\n\n\\section{Community Satisfaction}\n\\label{communittsatsec}\nKnowing that the question about community satisfaction was the only survey question answered by all respondents, it made sense to see which communities reported the highest levels of community satisfaction. \n\nTo visualize this, a set of stacked distribution graphs were created \\citep{RobHei2011}. These stacked distribution graphs are centered around zero and use a diverging color scale to give an overall graphical sense of the amount of positive and negative responses across groups. Figure \\ref{fig:communitysatplot} shows the distribution of responses to the question, ``Taking everything into account, how satisfied are you with this community as a place to live?'' and is ordered by the communities with the largest total positive responses in 2008, which highlights the changes in 2009 and 2010. \n\n%Should probably get these plots centered around 0, in other words they should go -75 to 75. \n\n<<LikertDataFunction>>=\nLikertData <- function(positive, negative, neutral=NULL, dataset){\n  pos <- dataset[dataset$Response %in% positive,]\n  neg <- dataset[dataset$Response %in% negative,]\n  if (is.null(neutral)==FALSE){\n    neu <- dataset[dataset$Response %in% neutral, ]\n    neu$Freq <- neu$Freq/2\n    pos <- rbind(pos, neu)\n    neg <- rbind(neg, neu)\n  } else {\n  neu <- NULL\n  }\n  neg$Freq <- -neg$Freq\n  neg$Response <- factor(neg$Response)\n  neg$Response <- factor(neg$Response, levels=rev(levels(neg$Response)))\n  pos$Response <- factor(pos$Response)\n  return(list(pos=pos, neu=neu, neg=neg))\n}\n@\n\n<<colors, echo=TRUE>>=\ncolors1 <- brewer.pal(5, \"Spectral\")\ncolors1\ncolorsA <- colors1[c(2,3,4,1,5)]\ncolorsB <- colors1[c(2,3,4,5,1)]\n@\n\n<<communitysat>>=\nsotc_df <- tbl_df(sotc10)\nsotc_df09 <- tbl_df(sotc09)\nsotc_df08 <- tbl_df(sotc08)\ntmp1 <- summarise(group_by(sotc_df08, citystate, community_sat), n = n()) %>% mutate(frac=prop.table(n), year=2008)\ntmp2 <- summarise(group_by(sotc_df09, citystate, community_sat), n = n()) %>% mutate(frac=prop.table(n), year=2009)\ntmp3 <- summarise(group_by(sotc_df, citystate, community_sat), n = n()) %>% mutate(frac=prop.table(n), year=2010)\n\ntmp <- rbind(tmp1, tmp2, tmp3)\ntmp <- rename(tmp, Response = community_sat, Freq = frac)\n\n#Now all I have to do is make the plot\nneutral <- c(\"3\")\npositive <- c(\"Extremely satisfied\", \"4\")\nnegative <- c(\"2\", \"Not at all satisfied\")\n\ntrial2 <- LikertData(positive, negative, neutral, tmp)\n\nextremelysat <- tbl_df(trial2$pos) %>% filter(year==2008) %>% group_by(citystate) %>% summarise(tot=sum(Freq)) \nmostsat <- order(extremelysat$tot)\n\ntrial2$pos$citystate <- factor(trial2$pos$citystate, levels=levels(trial2$pos$citystate)[mostsat])\ntrial2$neg$citystate <- factor(trial2$neg$citystate, levels=levels(trial2$neg$citystate)[mostsat])\ntrial2$neg$Response <- factor(trial2$neg$Response)\ntrial2$pos$Response <- factor(trial2$pos$Response)\ntrial2$neg$Response <- factor(trial2$neg$Response, levels=levels(trial2$neg$Response)[c(2,3,1)])\n\nposform <- trial2$pos\n\nmaconsat <- tbl_df(posform) %>% filter(citystate==\"Macon, GA\") %>% group_by(year) %>% summarise(totalper=sum(Freq))\nbrandetonsat <- tbl_df(posform) %>% filter(citystate==\"Bradenton, FL\") %>% group_by(year) %>% summarise(totalper=sum(Freq))\n@\n\n<<communitysatplot, fig.cap=\"Responses to the question, \\`\\`Taking everything into account, how satisifed are you with this community as a place to live?\\\" Communities are ordered by percentage of positive responses in 2008, making it clear the differences in distribution in 2009 and 2010.\", out.width=\"0.99\\\\linewidth\",fig.width = 9.5,fig.height=15,>>=\nbaseplot <- ggplot() + aes(x=citystate, y=Freq, fill = Response, order=Response)+facet_wrap(~year, nrow=3)\nbaseplot <- baseplot  +geom_bar(data = trial2$neg, stat = \"identity\") + scale_fill_manual(breaks=c(\"Not at all satisfied\", \"2\", \"3\", \"4\", \"Extremely satisfied\"), values=colors1, name=\"Response\") + geom_bar(data = trial2$pos, stat = \"identity\")\nbaseplot <- baseplot +coord_flip() + ggtitle(\"Community satisfaction\") + xlab(\"\") +ylab(\"\")+ggtitle(\"Community satisfaction\")\nbaseplot <- baseplot + scale_y_continuous(limits=c(-1, 1), breaks=seq(from=-1, to=1, by=0.25), labels=c(\"100%\", \"75%\", \"50%\", \"25%\", \"0\", \"25%\", \"50%\", \"75%\", \"100%\"))+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text=element_text(size=14), strip.text=element_text(size=14))\nbaseplot \n@\n\n\nOverall, the total percentage of positive responses in 2008 ranges between \\Sexpr{round(extremelysat[extremelysat$citystate==\"Gary, IN\",]$tot*100)}\\% on the low end, and \\Sexpr{round(extremelysat[extremelysat$citystate==\"State College, PA\",]$tot*100)}\\% at the high end. These numbers are the overall percentage of people in each community that are answering the question, ``Taking everything into account, how satisfied are you with this community as a place to live?'' positively (this includes half of the responses labeled 3).\n\nCommunities are ordered by overall positive responses in 2008, which allows for comparisons between communities and across years. The overall trend is fairly stable, but there is some variation, both positive and negative. Looking at Figure \\ref{fig:communitysatplot}, we can see that people in State College, PA typically report much greater levels of community satisfaction than people in Detroit, MI or Gary, IN. After 2008, Macon, GA sees a decrease in overall community satisfaction, moving from \\Sexpr{round(maconsat$totalper[1]*100)}\\% in 2008 to \\Sexpr{round(maconsat$totalper[2]*100)}\\% in 2009 and slightly up to \\Sexpr{round(maconsat$totalper[3]*100)}\\% in 2010. Over the same time period, Bradenton, FL shows a slight increase in community satisfaction, from \\Sexpr{round(brandetonsat$totalper[1]*100)}\\% in 2008 to about  \\Sexpr{round(brandetonsat$totalper[2]*100)}\\% in 2009 and 2010. \n\n\n\\section{Behaviors}\n\\label{behaviorsec}\nAnother point of interest was the most common behaviors reported by participants. Figure \\ref{fig:YNall} shows the percentage of participants engaging in a variety of behaviors over the three years of the survey. An additional set of questions were introduced in 2010, so those are necessarily blank in the previous years. \n\nBehaviors are arranged by percentage of survey respondents who reported the behavior. \nOver all three years, the most common behavior was being registered to vote, followed by voting in a local election. The least common responses to the behavior questions (considering all three years) were ``worked with other residents to make change in the local community'', and ``attended a local public meeting in which local issues were discussed.'' When the additional questions were added in 2010, an even-less-common behavior was added, ``gave money or food to an individual in need in your community who is not related to you.'' \n\n<<twolevel>>=\ntwolevel <- c(\"registered_vote\", \"volunteer\", \"public_meeting\", \"voted_local\", \"worked_change\", \"church\", \"festival\", \"donated_org\", \"donated_individual\", \"donated_shelter\")\n\n# Function that takes a dataset and calculates the percentages of cases overall\nfindPercen <- function(dataset){\n  dfall <- data.frame()\n  for (i in 1:length(twolevel)){\n  if(twolevel[i] %in% names(dataset)){\n      tmp <- data.frame(Question=twolevel[i], prop.table(table(dataset[,twolevel[i]])))\n      dfall <- rbind(dfall, tmp)\n  }\n  else{\n    tmp <- data.frame(Question=twolevel[i], Var1 = c(\"No\", \"Yes\"), Freq=c(NA, NA))\n    dfall <- rbind(dfall, tmp)\n  }\n}\nnames(dfall) <- c(\"Question\", \"Response\", \"Freq\")\nreturn(dfall)\n}\n\ndf10 <- findPercen(sotc10)\ndf10$Year <- 2010\ndf09 <- findPercen(sotc09)\ndf09$Year <- 2009\ndf08 <- findPercen(sotc08)\ndf08$Year <- 2008\n\ndfall <- rbind(df10, df09, df08)\ndfall$Question <- factor(dfall$Question, levels=levels(dfall$Question)[order(df10$Freq[df10$Response==\"Yes\"])])\npositive <- \"Yes\"\nnegative <- \"No\"\ntrial1 <- LikertData(positive, negative, neutral=NULL, dataset=dfall) \n@\n\n<<YNall, out.width=\"0.99\\\\linewidth\",fig.width = 15,fig.height=10.5,fig.cap=\"Responses to yes/no questions about participants' behaviors, comparing all three survey years.\">>=\nbaseplot <- ggplot() + aes(Question, Freq, fill = Response) +facet_wrap(~Year)\nbaseplot <- baseplot + geom_bar(data = trial1$neg, stat = \"identity\") + geom_bar(data = trial1$pos, stat = \"identity\")\nbaseplot <- baseplot +ggtitle(\"Yes/no questions\") + scale_y_continuous(breaks=seq(from=-0.75, to=0.75, by=0.25), labels=percent)\nbaseplot <- baseplot + coord_flip()+ xlab(\"\")\nbaseplot <- baseplot + scale_x_discrete(labels=rev(c(\"Registered to vote \\n\", \"Voted in local election \\n\", \"Donated money to a \\n local organization\", \"Attended a local \\n festival or event\", \"Gave money or food \\n to an individual\", \"Participated in a \\n church event\", \"Performed local \\n volunteer work\", \"Worked with other residents \\n to make change\", \"Attended a local \\n public meeting\", \"Provided free shelter \\n to an individual\")))\nbaseplot <- baseplot + ylab(\"\")+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text.y=element_text(size=20), title=element_text(size=24), axis.text.x=element_text(size=14), strip.text=element_text(size=18))\nbaseplot\n@\n\nA followup to this question is whether all communities performed these actions at similar rates, or if there were local variations in behavior. Figure \\ref{fig:YN2010plot} shows the difference from the overall rate across all 26 communities and 10 behaviors in 2010. More study is required to determine if the visual differences between communities represent true differences or just random variation, but there are certainly communities that stand out from the rest. \n\nFor example, people in St. Paul, MN, San Jose, CA, and State College, PA were much more likely than the average to to provide free shelter to a non-relative, while people in Georgia (both Macon and Milledgeville) were less likely to. This provides a connection to Figure \\ref{fig:communitysatplot}, because Macon and Milledgeville were the two communities whose community satisfaction scores decreased the most in 2009 and 2010, while San Jose was one of the most satisfied communities over all three years. One hypothesis is that St. Paul, San Jose, and State College are all university towns, where young people (especially college students) may invite friends and friends-of-friends to stay with them for free. Again, more study is required. \n\nIt is also interesting to note the communities that performed above or below national rates on most questions. For example, Biloxi, MS shows that respondents are much less likely to engage in any of the behaviors asked about, with the exception of being registered to vote and performing local volunteer work. On the other hand, Palm Beach, FL shows higher-than-average rates for almost all behavior, except for being registered to vote and giving money or food to an individual. Long Beach, CA shows a similar pattern. However, since this array of plots represents 26 facets of the same plot, it is possible that these visual trends occurred by chance. \n<<YN2010>>=\ndfall <- data.frame()\nfor (i in 1:length(twolevel)){\n  tmp <- data.frame(Question=twolevel[i], prop.table(table(sotc10[,twolevel[i]])))\n  dfall <- rbind(dfall, tmp)\n}\nnames(dfall) <- c(\"Question\", \"Response\", \"Freq\")\n\n\n# Create a loop that calculates the percentages of cases in each factor level for each city\ndfcities <- data.frame()\nfor (j in 1:length(levels(sotc10$citystate))){\n  thiscity <- subset(sotc10, citystate==levels(sotc10$citystate)[j])\n  for (i in 1:length(twolevel)){\n    tmp <- data.frame(levels(sotc10$citystate)[j], Question=twolevel[i], prop.table(table(thiscity[,twolevel[i]])))\n    dfcities <- rbind(dfcities, tmp)\n  }\n}\nnames(dfcities) <- c(\"citystate\", \"Question\", \"Response\", \"Freq\")\n\n\n# Lets see the difference between the overall and the cities to see where the variation comes from\ndfcities$diff <- 0\nfor (i in 1:length(levels(dfcities$Question))){\n  # Yes\n  overallrate <- dfall[dfall$Question==levels(dfall$Question)[i] & dfall$Response==\"Yes\",]$Freq\n  dfcities$diff[(dfcities$Question==levels(dfcities$Question)[i]& dfcities$Response==\"Yes\")] <- (overallrate - dfcities[(dfcities$Question==levels(dfcities$Question)[i] & dfcities$Response==\"Yes\"),]$Freq)/overallrate\n}\n\ndfcitiesYes <- dfcities[dfcities$Response==\"Yes\",]\ndfcitiesYes$col <- dfcitiesYes$dif>0\ndfcitiesYes$Question <- factor(dfcitiesYes$Question, levels=levels(dfcitiesYes$Question)[order(dfall[dfall$Response==\"Yes\",]$Freq)])\n@\n\n<<YN2010plot, out.width=\"0.99\\\\linewidth\",fig.width = 10,fig.height=18, fig.cap=\"Difference from overall survey rates (2010 data). The letters A-J represent the activities listed in Figure \\\\ref{fig:YNall}. A: Registered to vote, B: Voted in a local election, C: Donated money to a local organization, D: Attended a local event, E: Gave money or food to an individual, F: Participated in a church event, G: Performed local volunteer work, H: Worked with other residents to make change, I: Attended a local public meeting, J: Provided free shelter to an individual.\">>=\nbaseplot <- ggplot(dfcitiesYes) + aes(Question, diff, fill = col) + facet_wrap(~citystate, ncol=3) + geom_bar(stat = \"identity\")\nbaseplot <- baseplot +coord_flip()+ggtitle(\"Percentage difference from overall survey rates\")\nbaseplot <- baseplot + guides(fill=FALSE)+scale_y_continuous(breaks=seq(from=-.5, to=.5, by=.125),labels=c(\"50%\",\"\", \"25%\",\"\", \"0\",\"\", \"25%\",\"\", \"50%\"))+scale_x_discrete(labels=LETTERS[10:1])\nbaseplot <- baseplot + ylab(\"\") +xlab(\"\")+theme(axis.text.y=element_text(size=12), title=element_text(size=18), axis.text.x=element_text(size=14), strip.text=element_text(size=16))\nbaseplot\n@\n\n\\section{Meta-Knowledge}\n\\label{metasec}\nThe primary aim  of this article was to address whether communities held meta-knowledge about their city being a good place for subgroups or minorities. \n\nThe survey asks a number of questions related to rating the community as a place for subgroups, including: ``young, talented college graduates,'' ``immigrants from other countries,'' ``racial and ethnic minorities,'' ``families with young children,'' ``gay and lesbian people,'' ``senior citizens,'' and ``young adults without children.'' Not all these subgroups were asked to identify themselves in the demographic questions (particularly ``gay and lesbian people'') so it was not possible to address them all. Instead, we focus on senior citizens, families with young children, and racial and ethnic minorities.\n\nCommunity meta-knowledge is essentially majority group empathy or understanding of how minorities experience their community. For example, the survey asks participants to rate their community as a place for families with young children on a 5-point Likert scale. A city where participants with children rated their community in the same way as participants without children is defined as a community with high meta-knowledge about conditions for families with young children. \n\n\\subsection{Meta-knowledge about the community as a place for seniors}\n\\label{mseniors}\nIn order to determine if non-seniors understood how good their community was for seniors, the data was split into two pieces, one of participants aged 55 and older, and the other of participants under 55. For sample sizes of the groups, see Table \\ref{seniorSS}. Interestingly, the split between seniors and non-seniors was roughly 50/50 every year. \n\n<<OverallSeniors>>=\nseniorGroup10 <- filter(sotc10, seniors != \"NA\") %>% group_by(age >= 55, seniors) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2010)\nn1 <- c(\"InGroup\", \"Response\", \"n\", \"Freq\", \"year\")\nnames(seniorGroup10) <- n1\n\nseniorGroup09 <- filter(sotc09, age != \"NA\") %>% group_by(age >= 55, seniors) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2009)\nnames(seniorGroup09) <- n1\n\nseniorGroup08 <- group_by(sotc08, age >= 55, seniors) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2008)\nnames(seniorGroup08) <- n1\n\nseniorYears <- rbind(seniorGroup08, seniorGroup09, seniorGroup10)\nseniorYears$Response <- factor(seniorYears$Response, levels=levels(seniorYears$Response)[c(6,3:5, 7,1:2)])\n\n@\n\n<<seniorSS, out.width= \"0.99\\\\linewidth\", fig.width = 8.5, fig.height= 4.5, fig.cap = \"Sample sizes for plots about meta-knowledge regarding the community as a place for seniors.\">>=\nseniorSS <- tbl_df(seniorYears) %>% group_by(year, InGroup) %>% summarise(number=sum(n)) %>% mutate(percentage=(100*number)/sum(number))\nseniorSS$InGroup[seniorSS$InGroup==\"FALSE\"] <- \"Seniors\"\nseniorSS$InGroup[seniorSS$InGroup==\"TRUE\"] <- \"Non-seniors\"\nseniorplot <- ggplot(aes(x=year, y=number), data=seniorSS)+geom_bar(aes(fill=InGroup), position=\"dodge\", stat=\"identity\")+xlab(\"Year\")+ylab(\"Sample size\")+guides(fill=guide_legend(title=NULL))+scale_fill_grey(start=0.6, end=0.4)\nseniorplot\n@\n\n\n<<OverallSeniorRatings>>=\nneutral <- c(\"3\")\npositive <- c(\"Very good\", \"4\")\nnegative <- c(\"2\", \"Very bad\")\nseniorOverall <- LikertData(positive, negative, neutral, seniorYears)\n@\nThe yearly ratings distributions are shown in Figure \\ref{fig:seniorOverallPlot}. It appears that non-seniors typically underestimate how good a place is for seniors. People 55 and older rated their community as a better place for seniors than did people under 55, over all three years.  \n\n\n<<seniorOverallPlot,out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=6.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for seniors?\\\" Seniors are defined as survey participants aged 55 and older, non-seniors are those under 55. Notice that seniors consistently rated their community more highly than did non-seniors over all three survey years.\">>=\nbaseplot <- ggplot() + aes(InGroup, Freq, fill = Response, order=Response)+facet_wrap(~year, nrow=3)\nbaseplot <- baseplot + geom_bar(data = seniorOverall$neg, stat = \"identity\") + geom_bar(data = seniorOverall$pos, stat = \"identity\") + scale_fill_manual(breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"),values=colorsA, name=\"Response\")\nbaseplot <- baseplot +coord_flip()\nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Non-seniors\", \"Seniors\"))\nbaseplot <- baseplot + ggtitle(\"How is your community as a place for seniors?\") + xlab(\" \") + ylab(\"\")+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text.y=element_text(size=12), title=element_text(size=16), axis.text.x=element_text(size=12), strip.text=element_text(size=14))\nbaseplot\n@\n\nAgain, to investigate the local variations in responses, a faceted plot of responses between the two groups was created. This plot can be seen in Figure \\ref{fig:seniorPlot}, and it uses 2010 data. Interestingly, almost every community followed the trend of non-seniors underestimating how good their community was for seniors (or seniors boosting their responses). There was only one exception to this rule-- Milledgeville, GA. However, this could be due to random variation. \n<<seniorData>>=\n# The goal for this plot is to show the difference between the responses to questions by people in a particular group and those outside the group. \n# The groups are: seniors (55+), variable age and variable seniors, \nseniorGroup <- filter(sotc10, seniors != \"NA\") %>% group_by(citystate, age >= 55, seniors) %>% summarise( n = n()) %>% mutate(frac=prop.table(n))\nn2 <- c(\"citystate\", \"InGroup\", \"Response\", \"n\", \"Freq\")\nnames(seniorGroup) <- n2\nseniorGroup$Response <- factor(seniorGroup$Response, levels=levels(seniorGroup$Response)[c(4, 1:3, 5)])\n\nseniorGroup2 <- LikertData(positive, negative, neutral, seniorGroup)\nseniorGroup2$neg$Response <- factor(seniorGroup2$neg$Response)\nseniorGroup2$pos$Response <- factor(seniorGroup2$pos$Response)\nseniorGroup2$neg$Response <- factor(seniorGroup2$neg$Response, levels = levels(seniorGroup2$neg$Response)[c(2,3,1)])\n\n@ \n\n\n<<seniorPlot, out.width=\"0.99\\\\linewidth\",fig.width = 10.5,fig.height=12.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for seniors?\\\" faceted by community (2010 data). Every community follows the pattern of over-rating by seniors, but some communities have a smaller discrepency between ratings of seniors and non-seniors.\">>=\nbaseplot <- ggplot(seniorGroup) + aes(InGroup, Freq, fill = Response, order = Response) + facet_wrap(~citystate, ncol=3)\nbaseplot <- baseplot  + geom_bar(data = seniorGroup2$neg, stat = \"identity\") + geom_bar(data = seniorGroup2$pos, stat = \"identity\") + scale_fill_manual(breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"), values=colorsB, name=\"Response\")\nbaseplot <- baseplot +coord_flip() \nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Non-seniors\", \"Seniors\"))\nbaseplot <- baseplot + ggtitle(\"How is your community as a place for seniors?\") + xlab(\"\") + ylab(\"\")+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text.y=element_text(size=16), title=element_text(size=16), axis.text.x=element_text(size=12),strip.text=element_text(size=14))\nbaseplot\n@\n\n\\subsection{Meta-knowledge about the community as a place for families with young children}\nFor the exploration of meta-knowledge about communities as a place for families with young children, we split participants between those who reported having dependent children under the age of 18 living in their household and those who did not. Intuitively, it makes sense that a parent of an older child (say, a teenager) would have higher meta-knowledge about the community as a place for families with young children than a participant who never had children or whose children have grown up and moved away. While the data included more granular demographic details about the ages of the children in the households, splitting the data into participants with children and those without made the groups closer in size. To see the sample sizes and percentages, see Table \\ref{kidSS}. \n\n<<kidsByCity>>=\n# families with young children, variable children and raise kids, \n# Families with children\nkidGroup <- filter(sotc10, children == \"Yes\" | children == \"No\") %>% group_by(citystate, children, families_kids) %>% summarise(n = n()) %>% mutate(frac=prop.table(n))\nnames(kidGroup) <- n2\n\nkidGroups <- LikertData(positive, negative, neutral, kidGroup)\nkidGroups$neg$Response <- factor(kidGroups$neg$Response, levels=levels(kidGroups$neg$Response)[c(2,3,1)])\n@\n\n<<kidsbyYear>>=\nkidGroup10 <- filter(sotc10, children == \"Yes\" | children == \"No\", families_kids != \"NA\") %>% group_by(children, families_kids) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2010)\nnames(kidGroup10) <- n1\n\nkidGroup09 <- filter(sotc09, children == \"Yes\" | children == \"No\", families_kids != \"NA\") %>% group_by(children, families_kids) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2009)\nnames(kidGroup09) <- n1\n\nkidGroup08 <- filter(sotc08, children == \"Yes\" | children == \"No\", families_kids != \"NA\" & families_kids != \"(DK)\" & families_kids != \"(Refused)\") %>% group_by(children, families_kids) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2008)\nnames(kidGroup08) <- n1\n\nkidYears <- rbind(kidGroup08, kidGroup09, kidGroup10)\n@\n\n<<kidsSS,out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=4.5, fig.cap=\"Sample sizes for plots about meta-knowledge regarding the community as a place for families with young children.\">>=\nkidSS <- group_by(kidYears, year, InGroup) %>% summarise(number=sum(n)) %>% mutate(percentage=100*number/sum(number))\nlevels(kidSS$InGroup) <- c(\"Don't know\", \"Refused\", \"Childless households\", \"Families with children\")\n\nkidsplot <- ggplot(aes(x=year, y=number), data=kidSS)+geom_bar(aes(fill=InGroup), position=\"dodge\", stat=\"identity\")+xlab(\"Year\")+ylab(\"Sample size\")+guides(fill=guide_legend(title=NULL))+scale_fill_grey(start=0.6, end=0.4)\nkidsplot\n@\n\n<<kidsbyYearresponses>>=\nkidYears <- LikertData(positive, negative, neutral, kidYears)\nkidYears$neg$Response <- factor(kidYears$neg$Response, levels=levels(kidYears$neg$Response)[c(2,3,1)])\n@\n\n\nFigure \\ref{fig:kidsplotOverall} shows the difference between the ratings of the groups over the three years of the survey. As in Section \\ref{mseniors}, we can see that in-group ratings were slightly higher than out-group ratings, but the difference is not nearly as significant as in Section \\ref{mseniors} on seniors. In fact, both groups seem to give about the same ratings overall. This shows that meta-knowledge about the community as a place for families with young children is generally high (that is, people without children have a good idea how their community is for families with children).\n\nAgain, we broke this down by community for the 2010 data, as seen in Figure \\ref{fig:kidPlot}. Communities generally reflect the larger trend of good meta-knowledge outside the subgroup. Accordingly, the variation apparent in Figure \\ref{fig:kidPlot} is more about the overall ratings of the communities as places for raising kids. There was agreement both inside and outside the subgroup-- people seem to agree that State College, PA is a good place for families with young children, and Gary, IN and Macon, GA, are not. \n\n\n<<kidsplotOverall, out.width=\"0.99\\\\linewidth\",fig.width = 8.5, fig.height=6.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for families with young children?\\\" Families with children are defined as any household with children under the age of 18, Childless households are any households without children, whether or not the residents have adult children living elsewhere. Ratings were consistently similiar between groups and across survey years.\">>=\nbaseplot <- ggplot() + aes(InGroup, Freq, fill = Response, order=Response)+facet_wrap(~year, nrow=3)\nbaseplot <- baseplot + geom_bar(data = kidYears$neg, stat = \"identity\") + geom_bar(data = kidYears$pos, stat = \"identity\")+ scale_fill_manual(breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"),values=colorsA, name=\"Response\")\nbaseplot <- baseplot +coord_flip()\nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Childless \\n households\", \"Families \\n with children\"))\nbaseplot <- baseplot + ggtitle(\"How is your community as a place for families with young children?\") + xlab(\"\") + ylab(\"\")+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text.y=element_text(size=16), title=element_text(size=16), axis.text.x=element_text(size=14), strip.text=element_text(size=14))\nbaseplot\n@\n\n<<kidPlot, out.width=\"0.99\\\\linewidth\",fig.width = 8.5, fig.height=12.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for families with young children?\\\" faceted by community (2010 data). Interestingly, most communities follow the pattern of similar ratings by both groups, but there is a lot of variation between communities in terms of the overall rating.\">>=\nbaseplot <- ggplot() + aes(InGroup, Freq, fill = Response, order=Response)+facet_wrap(~citystate, ncol=3)\nbaseplot <- baseplot  +geom_bar(data = kidGroups$neg, stat = \"identity\") + geom_bar(data = kidGroups$pos, stat = \"identity\")+ scale_fill_manual(breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"),values=colorsB, name=\"Response\")\nbaseplot <- baseplot +coord_flip()\nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Childless \\n households\", \"Families \\n with children\"))\nbaseplot <- baseplot + ggtitle(\"How is your community for families with young children?\") + xlab(\" \") + ylab(\"\")+theme(legend.text=element_text(size=14), legend.title=element_text(size=16), axis.text.y=element_text(size=16), title=element_text(size=16), axis.text.x=element_text(size=10))\nbaseplot\n@\n\n\n\\subsection{Meta-knowledge about the community as a place for racial and ethnic minorities}\nInvestigating meta-knowledge about racial and ethnic minorities was more difficult than the previous subgroups, because each year of data collection used a slightly different set of possible answer choices to the question ``Which of these groups best describes your racial background?'' and because there were so many participants who refused to answer (particularly in 2010). \n\nTo see the overall distribution of responses to the demographic race question, see Figure \\ref{fig:overallRaceplot}.Notice that in 2010, the largest category was ``Refused,'' so Figure \\ref{fig:withoutRefused} shows the distributions without ``Refused'' responses. For absolute numbers and percentages for each of the race responses, see Table \\ref{racetable}. As the table shows, the sample sizes for individual minority race responses were somewhat small each year, so for the plots about subgroup meta-knowledge, we combined all the minority responses into one group that we refer to as Non-white. This category contains all participants who reported a race that was not White, but does not include participants who declined to give a response to the question. For a condensed summary of what the White/Non-white criteria means for the overall percentages, see Table \\ref{minorities}. \n<<minorities>>=\nraces10 <- filter(sotc10, race != \" \" & race != \"4\" & race != \"Don't Know\") %>% group_by(race) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2010)\nraces10$race <- factor(races10$race)\nlevels(races10$race) <- c(levels(races10$race)[1:5], \"Some other race\", levels(races10$race)[7])\n\nraces09 <- filter(sotc09, race != \" \" & race != \"4\" & race != \"Don't know\") %>% group_by(race) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2009)\nraces09$race <- factor(races09$race)\n\nraces08 <- filter(sotc08, race != \" \" & race != \"4\" & race != \"(DK)\" & race != \"None\") %>% group_by(race) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2008)\nraces08$race <- factor(races08$race)\nlevels(races08$race) <- c(\"Hispanic\", \"More than one\", \"Refused\", \"American Indian or Alaskan\", \"Asian\", \"Black or African-American\", \"Native Hawaiian or other Pacific Islander\", \"Some other race\", \"White\")\n\nraces <- rbind(races08, races09, races10)\nlevels(races$race)<- c(\"Asian\", \"Black or \\n African-American\", \"Hispanic\", \"Native Hawaiian \\n or other Pacific Islander\",\"Refused\", \"Some other \\n race\",  \"White\", \"American Indian \\n or Alaskan\",\"More than \\n one\")\n@\n\n<<overallRaceplot, out.width=\"0.99\\\\linewidth\",fig.width = 15,fig.height=10, fig.cap=\"Responses to the question, \\`\\`Which of these groups best describes your racial background?\\\" Notice that 2010 shows an overrepresentation of Refused responses, compared to the other years.\">>=\nraceOver <- ggplot() + aes(race, frac) + geom_bar(data=races, stat=\"identity\") + facet_wrap(~year,nrow=3) \nraceOver <- raceOver +ylab(\"Percent\")+xlab(\"\")+ scale_y_continuous(limits=c(0,1), labels=percent)\nraceOver <- raceOver+ggtitle(\"Overall distribution of race responses\")+theme(axis.text.y=element_text(size=20), title=element_text(size=24), axis.text.x=element_text(size=18),strip.text=element_text(size=25))\nraceOver\n@\n\n<<withoutRefused, out.width=\"0.99\\\\linewidth\",fig.width = 15,fig.height=10, fig.cap=\"The distribution of responses to the question, \\`\\`Which of these groups best describes your racial background?\\\" with Refused responses removed.\">>=\nwithoutRefused <- filter(races, race != \"Refused\") %>%group_by(year) %>% mutate(frac=prop.table(n))\n\nraceOver2 <- ggplot(withoutRefused) + aes(race, frac) + geom_bar(stat=\"identity\", drop=FALSE) + facet_wrap(~year,nrow=3) \nraceOver2 <- raceOver2 +ylab(\"Percent\")+xlab(\"\")+ scale_y_continuous(limits=c(0,1), labels=percent)\nraceOver2 <- raceOver2+ggtitle(\"Race response distribution without Refused responses\")+theme(axis.text.y=element_text(size=20), title=element_text(size=24), axis.text.x=element_text(size=18), strip.text=element_text(size=25))\nraceOver2\n@\n\n<<withoutRefusedTable, results='asis'>>=\nwithoutRefused$frac <- withoutRefused$frac*100\ncolnames(withoutRefused) <- c(\"Race\", \"Number of Responses\", \"Percent\", \"Year\")\n\nprint(xtable(withoutRefused[order(withoutRefused$Year),], caption=\"Absolute response numbers and percentages for race responses, with Refused responses removed.\", label=\"racetable\", display = c(\"d\", \"s\", \"d\",\"f\", \"d\" )), include.rownames = FALSE)\n@\n\nAs with the previous explorations of meta-knowledge, we look at the overall difference between in-group and out-group responses to the question, ``how is your community as a place for racial and ethnic minorities?'' Again, the data is split into two groups, one called White and one called Non-white. For comparison of the distribution of responses between groups, see Figure \\ref{fig:overallRaceResponsePlot}. Interestingly, Whites were rating their communities as better places for minorities than Non-whites in 2008 and 2009, but in 2010 Whites began under-rating their communities. \n\nAgain, we want to see the individual variation between communities. In the past few sections (on the quality of communities for seniors and families with children) we have been studying the 2010 data at the community level. However, as can be seen in Table \\ref{racetable}, the 2010 data has extremely low response rates to the demographic question about race and therefore, we chose to look at the 2009 data for community-level variation. The community-level responses are shown in Figure \\ref{fig:allMinorities}. There is a lot of variation between the communities for this particular type of meta-knowledge. Some communities saw the White respondents over-scoring their community as a place for minorities, while some were under-scoring. For the most part, however, Whites over-rated their communities as a place for racial and ethnic minorities, compared to Non-whites. Grand Forks, ND, was a particularly bad offender-- Whites over-rated it as a place for minorities, and minorities themselves rated it as one of the worst communities in 2009. \n\nThere was a lot of additional variation in response distribution. For example, San Jose, CA is highly rated as a place for minorities both by people in- and -outside the subgroup. And it was slightly under-rated by Whites, which is probably a good sign of meta-knowledge and empathy. Going the opposite direction are Grand Forks, ND, Myrtle Beach, SC, and Macon, GA. \n\n\n<<minoritiesOverYearsE>>=\nminoritiesYN08 <- filter(sotc08, race != \" \" & race != \"4\" & race != \"(DK)\" & race != \"None\" & race != \"(Refused)\") %>% group_by(citystate, race == \"White\", minorities) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2008)\nn3 <- c(\"citystate\", \"InGroup\", \"Response\", \"n\", \"Freq\", \"year\")\nnames(minoritiesYN08) <- n3\n\nminoritiesYN09 <- filter(sotc09, race != \" \" & race != \"4\" & race != \"Don't know\" & race != \"Refused\") %>% group_by(citystate, race == \"White\", minorities) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2009)\nnames(minoritiesYN09) <- n3\n\n\nminoritiesYN10 <- filter(sotc10, race != \" \" & race != \"4\" & race != \"Don't Know\" & race != \"Refused\") %>% group_by(citystate, race == \"White\", minorities) %>% summarise(n = n()) %>% mutate(frac=prop.table(n), year=2010)\nnames(minoritiesYN10) <- n3\n\nwhiteYN <- rbind(minoritiesYN08, minoritiesYN09, minoritiesYN10) %>% group_by(year, InGroup, Response) %>% summarise(Freq=mean(Freq))\nwhiteYears <- LikertData(positive, negative, neutral, whiteYN)\nwhiteYears$neg$Response <- factor(whiteYears$neg$Response, levels=levels(whiteYears$neg$Response)[c(3,2,1)])\n@\n\n<<overallRaceResponsePlot,  out.width=\"0.99\\\\linewidth\",fig.width = 8.5, fig.height=4.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for racial and ethnic minorities?\\\" White denotes survey respondents who listed their race as White, and Non-white is all other race responses (not including survey participants who refused to report a race). Notice the difference between the 2008/2009 responses and the 2010 responses, but also refer to Table \\\\ref{racetable} for the absolute sample sizes for each year-- 2010 has a much smaller sample of responses to the question overall.\">>=\nbaseplot <- ggplot() + aes(InGroup, Freq, fill = Response, order=Response)+facet_wrap(~year, nrow=3)\nbaseplot <- baseplot + geom_bar(data = whiteYears$neg, stat = \"identity\") + geom_bar(data = whiteYears$pos, stat = \"identity\") + scale_fill_manual(breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"), values=colorsB, name=\"Response\")\nbaseplot <- baseplot +coord_flip()\nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Non-white\", \"White\"))\nbaseplot <- baseplot + ggtitle(\"How is your community as a place for racial and ethnic minorities?\") + xlab(\"\") + ylab(\"\")\nbaseplot\n@\n\n<<samplesize, out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=4.5, fig.cap=\"Sample sizes for plots about meta-knowledge regarding the community as a place for minorities.\">>=\nwhiteYN1 <- tbl_df(whiteYN) %>% group_by(year, InGroup) %>% summarise(howmany=sum()) %>% mutate(frac=prop.table(howmany))\nwhiteplot <- ggplot(aes(x=year, y=howmany), data=whiteYN1)+geom_bar(aes(fill=InGroup), position=\"dodge\", stat=\"identity\")+xlab(\"Year\")+ylab(\"Sample size\")+guides(fill=guide_legend(title=NULL))+scale_fill_grey(start=0.6, end=0.4, labels=c(\"Non-white\",\"White\"))\nwhiteplot\n@\n\n<<allMinorities,out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=12.5, fig.cap=\"Responses to the question, \\`\\`How is your community as a place for racial and ethnic minorities?\\\" faceted by community (2009 data).\" >>=\n# minoritiesYN <- filter(sotc09, race != \" \" & race != \"4\" & race != \"Don't know\" & race != \"Refused\") %>% group_by(citystate, race == \"White\", minorities) %>% summarise(n = n()) %>% mutate(frac=prop.table(n))\n# \n# names(minoritiesYN) <- n2\n# \nminGroups <- LikertData(positive, negative, neutral, minoritiesYN09)\nminGroups$neg$Response <- factor(minGroups$neg$Response, levels=levels(minGroups$neg$Response)[c(2,3,1)])\n\n\n\nbaseplot <- ggplot() + aes(InGroup, Freq, fill = Response, order=Response)+facet_wrap(~citystate, ncol=3)\nbaseplot <- baseplot  +geom_bar(data = minGroups$neg, stat = \"identity\") + geom_bar(data = minGroups$pos, stat = \"identity\")+ scale_fill_manual(values=colorsB, breaks=c(\"Very bad\", \"2\", \"3\", \"4\", \"Very good\"),name=\"Response\")\nbaseplot <- baseplot +coord_flip()\nbaseplot <- baseplot + scale_y_continuous(breaks=seq(from=-0.25, to=0.75, by=0.25), labels=percent)+ scale_x_discrete(labels=c(\"Non-white\", \"White\"))\nbaseplot <- baseplot + ggtitle(\"How is your community as a place for minorities?\") + xlab(\"\") + ylab(\"\")+theme(title=element_text(size=14))\nbaseplot\n@\n\n\nFor another view of the relationship between ratings (as seen in Figure \\ref{fig:allMinorities}) see Figure \\ref{fig:anotherlookplot}, which shows the relationship between  total positive responses by Whites versus total positive responses by Non-whites to the question, ``How is your community as a place for racial and ethnic minorities?'' Figure \\ref{fig:anotherlookplot} makes it clear that there are communities that are under- and over-rated by Whites, and those that are closer to the 1-1 (or y=x) line. However, even if a community is on the 1-1 line, it may fall below the mean rating for communities overall. Gary, IN is a good example. While it is rated almost exactly the same by Whites and Non-whites, those ratings fall substantially below the mean ratings of communities overall. So, there is agreement that Gary is not a good place for minorities. \n\n<<anotherlook>>=\nwhiteFeelings <- tbl_df(minGroups$pos) %>% group_by(citystate, InGroup) %>% summarise(percents= sum(Freq))\nwhiteFeelings <- data.frame(whiteFeelings)\ndiffs <- whiteFeelings[whiteFeelings$InGroup==\"FALSE\",]$percents - whiteFeelings[whiteFeelings$InGroup==\"TRUE\",]$percents\nnewDF <- data.frame(whites=NA, nonwhite=NA, citystate=levels(whiteFeelings$citystate))\nnewDF$whites <- whiteFeelings[whiteFeelings$InGroup==\"TRUE\",]$percents\nnewDF$nonwhite <- whiteFeelings[whiteFeelings$InGroup==\"FALSE\",]$percents\n@\n\n<<anotherlookplot, fig.cap=paste0(\"Relationship between positive responses to the question, \\`\\`How is your community as a place for minorities?\\\" comparing ratings of Whites and Non-whites. Each community is represented, and the plot uses 2009 data. Some communitites, like State College, PA, are under-rated by Whites, some are over-rated, like Grand Forks, ND, and some are rated the same by both groups, like Gary, IN. The black line shows y=x, for comparison. Grey lines at x=\", round(mean(newDF$nonwhite), digits=2), \" and y=\", round(mean(newDF$whites), digits=2), \" show the mean ratings by each group.\")>>=\nal <- ggplot(newDF, aes(y=whites, x=nonwhite))+geom_vline(aes(x=mean(nonwhite)), color=\"grey\")+geom_hline(aes(y=mean(whites)), color=\"grey\")+geom_abline(intercept=0, slope=1)+ geom_point() + geom_text(data = newDF[newDF$citystate %in% c(\"Duluth, MN\", \"Gary, IN\", \"Grand Forks, ND\", \"State College, PA\"),], aes(y=whites,x=nonwhite, label = citystate), vjust=-0.1, hjust=0, size=4)+xlab(\"Non-whites rating\")+ylab(\"Whites rating\")+xlim(0.4, 0.8)+ylim(0.4, 0.6)+ggtitle(\"Relationship between ratings of the community as a place for minorities\")\n#hjust=c(-0.1,0,-0.1,0), vjust=c(3, 1, -5, -2),\nal\n@\n\n\n\n\\subsection{Generalizing with meta-knowledge}\nIdeally, we could use the information gathered about community meta-knowledge on subgroup experiences to determine more about the community itself. It's possible that meta-knowledge would correlate with other measures we are interested in (for example, overall community satisfaction or Gallup's favorite Community Attachment variable). \n\nFor the purpose of this analysis, we chose to define meta-knowledge about the community's quality for minorities as the difference between the total percentage of positive responses to the question, ``How is your community as a place for racial and ethnic minorities?\" by Non-whites and Whites, as seen in equation (\\ref{MK}). \n\n\\begin{eqnarray}\n\\label{MK}\nMK = \\sum R^{+}_{\\mbox{ Non-whites}} - \\sum R^{+}_{\\mbox{ Whites}}\n\\end{eqnarray}\n\nUsing this definition, communities where Whites highly over-rate their community as a place for minorities have a negative $MK$ score, while communities where Whites under-rate their community have a positive $MK$ score. Communities where the ratings by both groups are roughly equal (like Gary, IN) will have a $MK$ score of zero. For a visual explanation of this rating system, see Figure \\ref{fig:anotherlookplot}. Points above the $y=x$ line will have a negative $MK$ score, those below the line will have a positive score, and those on the line will be zero. \n\nThis definition puts emphasis on communities where out-of-subgroup participants rated their city the same way that in-subgroup participants did, based on the assumption that empathy is important to communities \\citep{SteFin1999} However, looking at Figure \\ref{fig:anotherlookplot}, we can see that there is another important factor, which does not seem to correlate with meta-knowledge-- ratings of the community by minorities themselves. \n\nIdeally, a community would be good for minorities, and Whites and Non-whites alike would know it. But, communities with scores near zero are spread over the whole range of the ratings by Non-whites. In other words, there are many communities with meta-knowledge but they really just have awareness of how bad their community is for minorities. The fact that White and Non-white residents of Gary, IN are in agreement that it is not a good place for minorities does not suggest it is a great place to live.\n\nIn order to explore this, we plotted raw $MK$ score against community satisfaction (from Section \\ref{communittsatsec}) and did not find a trend. Instead, it seemed like high $MK$ scores, both positive and negative, were associated with higher community satisfaction. So, Figure \\ref{fig:absdiff} shows the \nrelationship between the absolute value of meta-knowledge score, $|MK|$, and community satisfaction. \n\nFigure \\ref{fig:absdiff} shows a positive linear relationship between the variables, but it's not what we would expect. Communities that had the highest absolute difference in scoring of the question ``how is your community as a place for minorities?'' between Whites and Non-whites (and therefore the highest $|MK|$ score) had the highest community satisfaction scores. Communities that had low meta-knowledge score (like Gary, IN) have low community satisfaction scores. This seems counter-intuitive, as we would expect communities that had more self awareness to be more satisfied, but that's not what we see in the plot. However, the baseline Non-white rating of the community as a place for minorities is not displayed in this plot. \n\n\n<<scatterplot, out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=8.5, fig.cap=\"Relationship between mean community attachment and meta-knowledge, defined as the difference between Non-white and White ratings of their communities as a place for minorities (2009 data). Communitites where whites highly over-rate their community as a place for minorities are to the left of zero, while communitites where whites under-rate their community are shown to the right. Notice that there is little perceptable relationship between this definition of meta-knowledge and the mean community attachment score.\">>=\n\nCA09 <- group_by(sotc09, citystate) %>% summarise(aveCA = mean(CA, na.rm=TRUE)) %>% mutate(diffs=abs(diffs))\nCA09 <- data.frame(CA09)\n@\n\n<<absdiff, out.width=\"0.99\\\\linewidth\",fig.width = 8.5,fig.height=10, fig.cap=\"Relationship between community satisfaction and $|MK|$. Communities in the lower left corner had good agreement between Whites and Non-whites about whether their community was a good place for minorities, but a low community satisfaction. Communities in the upper right had a lot of discrepency between Whites and Non-whites, but high community community satisfaction. (2009 data).\">>=\n#CA2 <- CA09[,c(1:3)]\npositivesat <- tbl_df(posform) %>% filter(year==2009) %>% group_by(citystate) %>% summarise(newfrac=sum(Freq))\nCA3 <- merge(CA09, positivesat, by=\"citystate\")\nCA3$nonwhite <- whiteFeelings[whiteFeelings$InGroup==\"FALSE\",]$percents\nnames(CA3) <- c(\"citystate\", \"aveCA\", \"diffs\", \"communitysat\", \"nonwhite\")\n\n\nrelationplot2 <- ggplot(CA3, aes(y=communitysat, x=diffs, label=citystate)) + geom_point()+xlab(\"Absolute difference between minority and white ratings\")+ylab(\"Community satisfaction\")+ggtitle(\"Relationship between meta-knowledge and community satisfaction\") +xlim(0, 0.3)\nrelationplot2 <- relationplot2 + geom_text(data = CA3[CA3$citystate %in% c( \"Gary, IN\", \"Duluth, MN\", \"State College, PA\", \"Bradenton, FL\", \"Detroit, MI\" , \"Macon, GA\", \"Miami, FL\", \"Wichita, KS\", \"Grand Forks, ND\"),], aes(x=diffs,y=communitysat, label = citystate),hjust=-0.1, vjust=-0.4)\nrelationplot2+stat_smooth(method=\"lm\", se=FALSE)\n@\n\nA followup hypothesis is that meta-knowledge may not actually be good for a community. Perhaps the situation has to get quite bad before a community becomes meta-aware of how it actually treats minorities. In order to explore this hypothesis, we created the plot seen in Figure \\ref{fig:sizedbyratings}. Figure \\ref{fig:sizedbyratings} shows the same data as Figure \\ref{fig:absdiff}, with the addition of the points being sized by the percent of positive responses to the question, ``how is your community as a place for minorities?'' by Non-white respondents. From this plot, it seems plausible that the ratings by Non-white respondents are related to the relationship between community satisfaction and $|MK|$ score. \n\n<<sizedbyratings, fig.cap=\"Relationship between community satisfaction and $|MK|$, with points sized by Non-white ratings of their community as a place for minorities.\">>=\nrelationplot3 <- ggplot(CA3, aes(y=communitysat, x=diffs, label=citystate, size=nonwhite)) + geom_point()+xlab(\"Absolute difference between minority and white ratings\")+ylab(\"Community satisfaction\")+ggtitle(\"Relationship between meta-knowledge and community satisfaction\") +xlim(0, 0.3) \nrelationplot3 + scale_size_continuous(name=\"Percent positive \\n Non-white ratings\", labels=c(\"40%\", \"50%\", \"60%\", \"70%\", \"80%\"))\n@\n\n\nIn order to further study the trend, we fit the model seen in Table \\ref{model1}. This model takes into account the ratings of the community as a place for minorities, rated by Non-white respondents, as well as the $|MK|$ score, in predicting community satisfaction. \n<<goodmodel, results='asis'>>=\nnames(CA3) <- c(\"citystate\", \"Average Community Attachment\", \"|MK|\", \"Community satisfaction\", \"Non-white raings\")\nm12 <- lm(`Community satisfaction`~`|MK|`+`Non-white raings`, data=CA3)\nprint(xtable(summary(m12), caption=\"Linear model predicting 2009 community satisfaction scores using $|MK|$ and ratings by Non-white respondents.\", label=\"model1\"))\n@\n\nAll the terms in the model are significant at the 10\\% level, which admittedly isn't very high, but suggests there may be something to the model. The model tells us that without any information about $|MK|$ or Non-white ratings, we would predict a community satisfaction rating of 47\\%. However, for every one unit increase in $|MK|$, we would see a 9 point increase in community satisfaction rating. Similarly, for every one point increase in Non-white ratings, we would expect to see a 3.5 point increase in community satisfaction rating. \n\nInterestingly, this relationship can also be seen with Gallup Poll's favorite composite variable, Community Attachment (discussed in Section \\ref{data}). For those model estimates, see Table \\ref{model2}.\n\n<<CAmodel, results='asis'>>=\nm13 <- lm(`Average Community Attachment`~`|MK|`+`Non-white raings`, data=CA3)\nprint(xtable(summary(m13), caption=\"Linear model predicting average 2009 Community Attachment scores using $|MK|$ and ratings by Non-white respondents.\", label=\"model2\"))\n@\n\nBoth these models explain only a small portion of the variability in the data, but intuitively it makes sense that there would be other factors influencing overall community satisfaction or attachment. However, it is interesting to think about the relationships shown here. Essentially, communities where Whites were over- or under-rating their community as a place for minorities have higher community satisfaction, as do communities with higher Non-white ratings of the community as a place for minorities. This is interesting, because it suggests that overall community satisfaction is related to the satisfaction of a minority group. \n\nOf course, even these minor conclusions are not very conclusive. We're working with a non-random sample of communities, and a small one at that. However, the relationships studied here can point to areas for further study. \n\n\\section{Conclusions and Further Work}\nThrough this exploration of the Knight Foundation's Soul of the Community data, we have been able to examine variability between communities and theorize about what might affect those variations. In Section \\ref{communittsatsec} we saw which communities reported the highest levels of community satisfaction, namely State College, PA and Boulder, CO. In Section \\ref{behaviorsec}, we explored the common behaviors that survey participants engaged in, including registering to vote and voting in local elections. We noticed that college towns tend to have higher than typical rates of providing shelter to a non-relative (the couchsurfing effect?). \n\nThen, in Section \\ref{metasec} we began to explore community meta-knowledge, or how aware survey participants are about their community as a place for minority groups. We noticed that non-seniors almost always under-rate how good their community is for seniors, while communities tend to have high meta-knowledge about how good their community is for families with young children (though there are exceptions). Finally, we explored meta-knowledge about how good a community is for racial and ethnic minorities. This was the most challenging, and had the highest potential for payoff, but the results were different than we expected. We were able to expose variation between cities, years, and groups, but it is still not clear how useful this meta-knowledge could be as a measure of the soul of the community. \n\nLooking at it community satisfaction, we found that the linear trend was in the opposite direction than we had expected. However, when used in conjunction with overall Non-white ratings of a community, meta-knowledge could be used to somewhat successfully predict both community satisfaction and Community Attachment. For future work, it would be fascinating to track down why this trend is so different than one's assumptions. Are people happier in communities with low meta-knowledge, or where people in- and outside subgroups have very different experiences?\n\nIt would also be interesting to explore whether meta-knowledge on other subgroups, like seniors and families with children, can be used to model community satisfaction or Community Attachment. Unfortunately, this was outside the scope of this exploration. \n\n\\bibliographystyle{plainnat}\n\\bibliography{SoCbib.bib}\n\\end{document}",
    "created" : 1399330905887.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "45|25|47|2|\n57|13|61|1|\n62|13|71|1|\n83|19|93|1|\n95|432|99|1|\n104|359|132|1|\n140|17|143|1|\n153|37|161|1|\n171|23|189|1|\n252|13|284|1|\n286|175|294|1|\n301|11|333|1|\n335|568|341|1|\n",
    "hash" : "3651677448",
    "id" : "4C83349A",
    "lastKnownWriteTime" : 1425510898,
    "path" : "~/Dropbox/Projects/SoulOfCommunity/PaperDraft1.Rnw",
    "project_path" : "PaperDraft1.Rnw",
    "properties" : {
        "ignored_words" : "Likert,sotc,Brandeton,Milledgeville,Gallup's,ggplot\n"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "sweave"
}